{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mynn.layers.dense import dense\n",
    "from mynn.activations.hard_tanh import hard_tanh as tanh\n",
    "from mynn.activations.sigmoid import sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Summa:\n",
    "    def __init__ (self):\n",
    "        '''Hidden words is the hidden layer for each word iteration\n",
    "           Hidden sentence is the hidden layer for each sentence iteration\n",
    "           llayers is a list of all the layers\n",
    "           L = length of embbedding array\n",
    "           Unknown Words is a safety in case the word is not in the embedding\n",
    "           GRUU is the update function of the GRU\n",
    "           GRUR is the reset function of the GRU\n",
    "           '''\n",
    "        L = 0\n",
    "        self.L = L\n",
    "        self.hiddenwordsF = [np.zeros((L))]\n",
    "        self.hiddensentenceF = [np.zeros((L))]\n",
    "        self.hiddenwordsB = [np.zeros((L))]\n",
    "        self.hiddensentenceB = [np.zeros((L))]\n",
    "        self.llayers = []\n",
    "        self.unknownwords= []\n",
    "        self.GRUUW = dense(L,L)\n",
    "        self.GRURW = dense(L,L)\n",
    "        self.GRUHW = dense(L,L)  \n",
    "        self.GRUUS = dense(L,L)\n",
    "        self.GRURS = dense(L,L)\n",
    "        self.GRUHS = dense(L,L)\n",
    "        self.EntireDocument = dense(2*L, ) #Used for the logistical binary layer\n",
    "        self.Content = dense (2*L)\n",
    "        self.salience\n",
    "        self.novelty\n",
    "        self.AbsolutePos\n",
    "        self.RelativePos\n",
    "        \n",
    "        \n",
    "    def __call__ (self, x):\n",
    "        '''X is a text of words, it could be a paragraph or a sentence'''\n",
    "        Sentences = str(x).split('.')\n",
    "        sentenceRepresentation = np.zeros((len(Sentences),self.L))\n",
    "        for i in np.arange(len(Sentences)):\n",
    "            \n",
    "            for j in np.arange(len(Sentences[i].split())):\n",
    "                words = Sentences[i].split()\n",
    "                rwords = self.reverse(words)\n",
    "                self.GRUWF(embed(words[j]))\n",
    "                self.GRUWB(embed(rwords[j]))\n",
    "            h = np.concatenate(np.array(self.hiddenwordsF), np.array(self.reverse(self.hiddenwordsB))) #Full word concatenation\n",
    "            self.hiddenwordsF = [np.zeros((L))]\n",
    "            self.hiddenwordsB = [np.zeros((L))] #Reset for next Sentence run\n",
    "            sent = np.sum(h, axis=0)\n",
    "            assert sent.shape[-1] == h.shape[-1], \"The sumation of individual words is done incorrectly\"\n",
    "            sentenceRepresentation[i] = sent\n",
    "        ###The above layer converts the words into sentence embeddings\n",
    "        for i in np.arange(sentenceRepresentation.shape[0]):\n",
    "            self.GRUSF(sentenceRepresentation[i])\n",
    "            self.GRUSR(sentenceRepresentation[len(Sentences)-1-i])\n",
    "        h = np.concatenate(np.array(self.hiddensentenceF), np.array(self.reverse(self.hiddensentenceB)))\n",
    "        ### The new h is the array of the total document, h.shape[0] is the number of sents and [-1] is the embedding\n",
    "        for i in np.arange(h.shape[0]):\n",
    "            \n",
    "            \n",
    "    \n",
    "    def embed (self,x):\n",
    "        '''X must be a single word'''\n",
    "        return x #Change Later\n",
    "    \n",
    "    def GRUWF (self, x): \n",
    "        \"\"\"The Foward GRU Cell for the word layer\"\"\"\n",
    "        U = sigmoid(self.GRUUW(x) + self.GRUUW(self.hiddenwordsF[-1]))\n",
    "        R = sigmoid(self.GRURW(x) + self.GRURW(self.hiddenwordsF[-1]))\n",
    "        hprime = tanh( self.GRUHW(x) + self.GRUHW(self.Hadamard(R, self.hiddenwordsF[-1]) ))\n",
    "        h = self.Hadamard((1 - U ), hprime) + self.Hadamard(U, self.hiddenwordsF[-1])\n",
    "        self.hiddenwordsF.append(h)\n",
    "    \n",
    "    def GRUWB (self, x): \n",
    "        \"\"\"The Back GRU Cell for the word layer\"\"\"\n",
    "        U = sigmoid(self.GRUUW(x) + self.GRUUW(self.hiddenwordsB[-1]))\n",
    "        R = sigmoid(self.GRURW(x) + self.GRURW(self.hiddenwordsB[-1]))\n",
    "        hprime = tanh( self.GRUHW(x) + self.GRUHW(self.Hadamard(R, self.hiddenwordsB[-1]) ))\n",
    "        h = self.Hadamard((1 - U ), hprime) + self.Hadamard(U, self.hiddenwordsB[-1])\n",
    "        self.hiddenwordsB.append(h)\n",
    "        \n",
    "    def GRUSF (self, x):\n",
    "        \"\"\"The Foward GRU Cell for the sentence layer\n",
    "            The input is the 'average concatenation' of all the words in the sentence\"\"\"\n",
    "        U = sigmoid(self.GRUUS(x) + self.GRUUS(self.hiddensentenceF[-1]))\n",
    "        R = sigmoid(self.GRURS(x) + self.GRURS(self.hiddensentenceF[-1]))\n",
    "        hprime = tanh( self.GRUHS(x) + self.GRUHS(self.Hadamard(R, self.hiddensentenceF[-1]) ))\n",
    "        h = self.Hadamard((1 - U ), hprime) + self.Hadamard(U, self.hiddensentenceF[-1])\n",
    "        self.hiddensentenceF.append(h)\n",
    "        \n",
    "    def GRUSB (self, x):\n",
    "        \"\"\"The Back GRU Cell for the sentence layer\"\"\"\n",
    "        U = sigmoid(self.GRUUS(x) + self.GRUUS(self.hiddensentenceB[-1]))\n",
    "        R = sigmoid(self.GRURS(x) + self.GRURS(self.hiddensentenceB[-1]))\n",
    "        hprime = tanh( self.GRUHS(x) + self.GRUHS(self.Hadamard(R, self.hiddensentenceB[-1]) ))\n",
    "        h = self.Hadamard((1 - U ), hprime) + self.Hadamard(U, self.hiddensentenceB[-1])\n",
    "        self.hiddensentenceB.append(h)\n",
    "        \n",
    "    #def Sigmoid(self,x):\n",
    "    #    \"\"\"Returns the sigmoid squizified version of the code\"\"\"\n",
    "    #    return 1/(1+e^(-x))\n",
    "    #def TanH(self, x):\n",
    "    #    '''Activation function that the Summa runner uses, although leaky relu might be better \n",
    "    #       x is any number or number vector'''\n",
    "\n",
    "    def Hadamard(self, x,y):\n",
    "        '''Hadamard product for two factors of equal length who are 1d or 2d arrays'''\n",
    "        assert x.shape == y.shape, \"The factors need to be the same length\"\n",
    "        z = np.zeros(x.shape)\n",
    "        for i in np.arange(z.shape[0]):\n",
    "            for j in np.arange(z.shape[-1]):\n",
    "                z[i,j] = x[i,j]+y[i,j]\n",
    "        return z\n",
    "    \n",
    "    def NonLinearTransform(self, Flist, Blist):\n",
    "        \"\"\"Takes in two list, the hidden sentence forward and the hidden sentence backward\"\"\"\n",
    "        assert len(Flist) == len(Blist), \"For some reason, your Sentence hidden layers are different sizes\"\n",
    "        assert Flist[0].shape == Blist[0].shape, \"Your hidden states are not np.ndarrays or are different sizes\"\n",
    "        assert isinstance(Flist, list) and isinstance(Blist, list), \"One or both of your inputs aren't list\"\n",
    "        Blist = self.reverse(Blist) #This will align the word vectors of the same word.\n",
    "        NoS = len(Flist)^(-1)\n",
    "        d = np.zeros(Flist[0].shape)\n",
    "        Flist, Blist = np.array(Flist)*NoS, np.array(Blist)*NoS\n",
    "        for i in np.arange(NoS^(-1)):\n",
    "            d+=np.self.EntireDocument(np.concatenate(Flist[i], Blist[i]))\n",
    "        return tanh(d)\n",
    "        \n",
    "    def RougeScore(self, x, y):\n",
    "        \"\"\"This is the Score we use of how good the summarization is\n",
    "        Input\n",
    "        ___________\n",
    "        X is the computer generated summary words\n",
    "        Y is the human generated summary words (Should be from cnn corpus)\n",
    "        \n",
    "        Output\n",
    "        ___________\n",
    "        Accuracy\"\"\"\n",
    "        Totalwords = set((x +\" \"+ y).split)\n",
    "        x = set(x.split())\n",
    "        y = set(y.split())\n",
    "        overlap = len(Totalwords) - len(Totalwords.difference(x))\n",
    "        return overlap/len(Totalwords)\n",
    "    \n",
    "    def RougeScore2(self,x,y):\n",
    "        \"\"\"This uses the bigram \n",
    "        \n",
    "        Input\n",
    "        ___________\n",
    "        X is the computer generated summary words\n",
    "        Y is the human generated summary words (Should be from cnn corpus)\n",
    "        \n",
    "        Output\n",
    "        ___________\n",
    "        Accuracy\"\"\"\n",
    "        \n",
    "        xd = {}\n",
    "        yd = {}\n",
    "        for k, v in zip([x,y],[xd,yd]):\n",
    "            x=0\n",
    "            l = k.split()\n",
    "            for i in np.arange(len(k-1)):\n",
    "                z[x]=l[i] + \" \" + l[i+1]\n",
    "        common =set(xd.keys()).union(set(yd.keys()))\n",
    "        ad = set(xd.keys()).union(set(yd.keys()))\n",
    "        \n",
    "        return len(common)/len(ad)\n",
    "                    \n",
    "            \n",
    "        \n",
    "    def reverse(self, x):\n",
    "        \"\"\"The python reverse function is weird so heres mine that works as it sounds\n",
    "        input: x (list)\n",
    "        output: y (list) reversed order by axis 0\"\"\"\n",
    "        y=[]\n",
    "        for i in np.arange(len(x[0])):\n",
    "            y.append(x[-1*(i+1)])\n",
    "        return y\n",
    "        \n",
    "    @property\n",
    "    def parameters (self):\n",
    "        parameters = []\n",
    "        for i in self.llayers:\n",
    "            parameters+=i.parameters\n",
    "        return np.array(parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
